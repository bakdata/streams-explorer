graph:
  # render graph every x seconds
  update_interval: 30
  layout_arguments: "-Grankdir=LR -Gnodesep=0.8 -Gpad=10"
  pipeline_distance: 500
  resolve:
    input_pattern_topics:
      # If true topics that match (extra) input pattern(s) are connected to the streaming app in the graph containing all pipelines
      all: false
      # If true topics that match (extra) input pattern(s) are connected to the streaming app in pipeline graphs
      pipelines: false

k8s:
  deployment:
    cluster: false
    # not needed if in cluster
    context: "kubernetes-cluster"
    namespaces:
      - "kubernetes-namespace"
  # used to extract the consumer group for metrics (e.g. consumer lag)
  consumer_group_annotation: "consumerGroup"
  containers:
    ignore:
      - name: "prometheus-jmx-exporter"
  displayed_information:
    - name: "Labels"
      key: "metadata.labels"
  labels:
    # used to set attributes of nodes in the graph (used to extract pipeline names)
    - "pipeline"
  pipeline:
    # refers to the attribute of nodes the pipeline name should be extracted from
    label: "pipeline"

kafka:
  enable: false
  # librdkafka configuration properties
  # https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md
  config:
    bootstrap.servers: "localhost:9092"
  displayed_information:
    - name: "Cleanup Policy"
      key: "cleanup.policy"
  # cache for retrieving all topic names (used when input topic patterns are resolved)
  topic_names_cache:
    ttl: 3600

node_info:
  # cache time-to-live in seconds
  cache_ttl: 3600

# (optional) configure Kafka Connect url and displayed information
# kafkaconnect:
#   url: "http://localhost:8083"
#   # fetch connectors every x seconds
#   update_interval: 300
#   displayed_information:
#     - name: "Transformer"
#       key: "transforms.changeTopic.regex"
#     - name: "Type"
#       key: "transforms.changeTopic.type"

## (optional) configure Schema Registry for topic information (supports Karapace and Confluent Schema Registry)
# schemaregistry:
#   url: "http://localhost:8081"

prometheus:
  url: "http://localhost:9090"

## (optional) choose either AKHQ or Redpanda Console to be used as message viewer in the linker
## enable one of them only
akhq:
  enable: false
  url: "http://localhost:8080"
  cluster: "kubernetes-cluster"
  ## (optional) connect name
  # connect: "kafka-connect"

redpanda_console:
  enable: false
  url: "http://localhost:8080"

grafana:
  enable: false
  url: "http://localhost:3000"
  dashboards:
    topics: "path/to/dashboard"
    consumergroups: "path/to/dashboard"

## (optional) choose either Kibana or Loki to be used as logging provider in the linker
## enable one of them only
kibanalogs:
  enable: false
  url: "http://localhost:5601"

loki:
  enable: false
  url: "http://localhost:3000"

esindex:
  url: "http://localhost:5601/app/kibana#/dev_tools/console"

plugins:
  path: "./plugins"
  extractors:
    default: true
